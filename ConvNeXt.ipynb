{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj1LT6gRgP7c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = \"/content/tiny-imagenet-200\"\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "images_dir = os.path.join(val_dir, \"images\")\n",
        "ann_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
        "\n",
        "# Read annotations\n",
        "with open(ann_file) as f:\n",
        "    annotations = [line.strip().split('\\t') for line in f]\n",
        "\n",
        "# Create class folders and move images\n",
        "for img, cls, *_ in annotations:\n",
        "    cls_dir = os.path.join(val_dir, cls)\n",
        "    os.makedirs(cls_dir, exist_ok=True)\n",
        "    shutil.move(\n",
        "        os.path.join(images_dir, img),\n",
        "        os.path.join(cls_dir, img)\n",
        "    )\n",
        "\n",
        "os.rmdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2c6qbU7gnwc",
        "outputId": "1bbab15d-ec66-4069-e60e-3cb6b247ae46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFcM5LRRgqZT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfla\n",
        "import tensorflow.keras.models as tfm\n",
        "import tensorflow.keras.optimizers as tfo\n",
        "import tensorflow.keras.losses as tflo\n",
        "import matplotlib.pyplot as plt\n",
        "from official.vision.ops import augment\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X0BB9Sygv6Y",
        "outputId": "2000010f-9524-425e-855d-aac820ccfa4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100000 files belonging to 200 classes.\n",
            "Found 10000 files belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "with open(\"tiny-imagenet-200/wnids.txt\") as f:\n",
        "    wnids = [line.strip() for line in f]\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(256, 256),\n",
        "    batch_size=None,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/val\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXSCkdK6gyeR"
      },
      "outputs": [],
      "source": [
        "def crop_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  image = tf.image.random_crop(image, (224, 224, 3))\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBFbzn8og0EI"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(crop_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBAeCgxTg1n0"
      },
      "outputs": [],
      "source": [
        "def apply_randaugment(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  augmenter = augment.RandAugment(num_layers=2, magnitude=9)\n",
        "  return augmenter.distort(image), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhBc6LBTg3H9"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(apply_randaugment, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK1clfAKg4oY"
      },
      "outputs": [],
      "source": [
        "def normalise_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  mean = tf.constant([0.485, 0.456, 0.406])\n",
        "  std = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "  image = (image / 255.0 - mean) / std\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD6c7F38g6ED"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YosysHgg7lM"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(128)\n",
        "combined_ds = train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EhlEef-g9Ce"
      },
      "outputs": [],
      "source": [
        "def mixup(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  images_lam = tf.reshape(lam, [-1, 1, 1, 1])\n",
        "  labels_lam = lam\n",
        "\n",
        "\n",
        "  images = images_lam * images + (1 - images_lam) * shuffled_images\n",
        "  labels = labels_lam * labels + (1 - labels_lam) * shuffled_labels\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m4G38fUg-gz"
      },
      "outputs": [],
      "source": [
        "mixup_ds = train_ds.map(mixup, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(mixup_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDWPStMGhBHQ"
      },
      "outputs": [],
      "source": [
        "def cutmix(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  cut_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  cut_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(cut_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - cut_height // 2, tf.int32)\n",
        "  cut_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_x = cut_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(cut_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - cut_width // 2, tf.int32)\n",
        "  cut_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_y = cut_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(cut_centre_x, tf.int32) - cut_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(cut_centre_x, tf.int32) + cut_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(cut_centre_y, tf.int32) - cut_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(cut_centre_y, tf.int32) + cut_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32) + shuffled_images * tf.cast(mask, dtype=tf.float32)\n",
        "  labels = labels * (1.0 - lam) + shuffled_labels * lam\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkE05nE2hDhb"
      },
      "outputs": [],
      "source": [
        "cutmix_ds = train_ds.map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(cutmix_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62qyAS0ahFEB"
      },
      "outputs": [],
      "source": [
        "def erase(images, labels):\n",
        "  # images shape: [batch_size, h, w, c]\n",
        "  # labels shape: [batch_size, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = tf.random.uniform(shape=(batch_size, 1), minval=0.2, maxval=0.5, dtype=tf.float32)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  erase_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  erase_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(erase_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - erase_height // 2, tf.int32)\n",
        "  erase_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_x = erase_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(erase_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - erase_width // 2, tf.int32)\n",
        "  erase_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_y = erase_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(erase_centre_x, tf.int32) - erase_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(erase_centre_x, tf.int32) + erase_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(erase_centre_y, tf.int32) - erase_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(erase_centre_y, tf.int32) + erase_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPNKk93BhGqK"
      },
      "outputs": [],
      "source": [
        "erase_ds = train_ds.map(erase, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(erase_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw2PMFHrhH_2"
      },
      "outputs": [],
      "source": [
        "def label_smoothing(labels, epsilon=0.1):\n",
        "  num_class = tf.cast(tf.shape(labels)[1], tf.float32)\n",
        "  return labels * (1.0 - epsilon) + epsilon / num_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPWLXMJ1hJUI"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.map(lambda images, labels: (images, label_smoothing(labels)), num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rx5UvOLhK5Y"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.shuffle(buffer_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dWbK-6_hRN0"
      },
      "outputs": [],
      "source": [
        "class block(tfla.Layer):\n",
        "  def __init__(self, C):\n",
        "    super().__init__()\n",
        "    self.C = C\n",
        "\n",
        "    self.dwconv = tfla.DepthwiseConv2D(\n",
        "        kernel_size=7,\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        depth_multiplier=1,\n",
        "        use_bias=True\n",
        "    )\n",
        "\n",
        "    self.layernor = tfla.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.pw1 = tfla.Dense(C * 4, activation=\"gelu\", use_bias=True)\n",
        "    self.pw2 = tfla.Dense(C, use_bias=True)\n",
        "\n",
        "    self.gamma = self.add_weight(\n",
        "        name=\"gamma\",\n",
        "        shape=[1, 1, 1, C],\n",
        "        initializer=tf.initializers.Constant(1e-6),\n",
        "        trainable=True\n",
        "    )\n",
        "\n",
        "  def dropLayer(self, x, drop_rate, training):\n",
        "    # x shape:[B, H, W, C]\n",
        "    B = tf.shape(x)[0]\n",
        "\n",
        "    if not training or drop_rate == 0:\n",
        "      return x\n",
        "\n",
        "    keep_rate = 1 - drop_rate\n",
        "\n",
        "    mask = tf.random.uniform(shape=(B, 1, 1, 1), minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "    mask = tf.floor(mask + keep_rate)\n",
        "\n",
        "    x = x * tf.cast(mask, tf.float32) / keep_rate\n",
        "\n",
        "    return x\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    # x shape:[B, H, W, C]\n",
        "    shortcut = x\n",
        "    x = self.dwconv(x)\n",
        "    x = self.layernor(x)\n",
        "    x = self.pw1(x)\n",
        "    x = self.pw2(x)\n",
        "\n",
        "    x = self.gamma * x\n",
        "\n",
        "    x = self.dropLayer(x, 0.1, training)\n",
        "\n",
        "    return x + shortcut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8-EQOinqGk4"
      },
      "outputs": [],
      "source": [
        "class down_sample(tfla.Layer):\n",
        "  def __init__(self, out_dim):\n",
        "    super().__init__()\n",
        "    self.layernor = tfla.LayerNormalization(epsilon=1e-6)\n",
        "    self.conv = tfla.Conv2D(filters=out_dim, kernel_size=2, strides=2, padding=\"valid\")\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layernor(x)\n",
        "    x = self.conv(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0z9tQ0VrJUF"
      },
      "outputs": [],
      "source": [
        "inputs = tfla.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = tfla.Conv2D(filters=96, kernel_size=4, strides=4, padding=\"valid\", use_bias=True)(inputs)\n",
        "x = tfla.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "for _ in range(3):\n",
        "  x = block(C=96)(x)\n",
        "\n",
        "x = down_sample(out_dim=192)(x)\n",
        "\n",
        "for _ in range(3):\n",
        "  x = block(C=192)(x)\n",
        "\n",
        "x = down_sample(out_dim=384)(x)\n",
        "\n",
        "for _ in range(9):\n",
        "  x = block(C=384)(x)\n",
        "\n",
        "x = down_sample(out_dim=768)(x)\n",
        "\n",
        "for _ in range(3):\n",
        "  x = block(C=768)(x)\n",
        "\n",
        "x = tfla.GlobalAveragePooling2D()(x)\n",
        "x = tfla.LayerNormalization(epsilon=1e-6)(x)\n",
        "x = tfla.Dense(units=200, activation=\"softmax\")(x)\n",
        "\n",
        "model = tfm.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-lZ5vy9w9j7",
        "outputId": "ad36c192-146f-45af-f8ec-155c90f7f398"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ down_sample (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">down_sample</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">306,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">306,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">306,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ down_sample_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">down_sample</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ down_sample_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">down_sample</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,184</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,763,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,763,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,763,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,800</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │         \u001b[38;5;34m4,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m192\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block (\u001b[38;5;33mblock\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m79,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_1 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m79,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_2 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m79,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ down_sample (\u001b[38;5;33mdown_sample\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │        \u001b[38;5;34m74,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_3 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m306,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_4 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m306,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_5 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m306,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ down_sample_1 (\u001b[38;5;33mdown_sample\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m295,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_6 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_7 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_8 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_9 (\u001b[38;5;33mblock\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_10 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_11 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_12 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_13 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_14 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,201,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ down_sample_2 (\u001b[38;5;33mdown_sample\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m1,181,184\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_15 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m4,763,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_16 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m4,763,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_17 (\u001b[38;5;33mblock\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m4,763,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │         \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m153,800\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,973,928</span> (106.71 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,973,928\u001b[0m (106.71 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,973,928</span> (106.71 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,973,928\u001b[0m (106.71 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwR_Hyw26z78"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = 3128\n",
        "epochs = 40\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=5e-4,\n",
        "    decay_steps=total_steps,\n",
        "    alpha=1e-2\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=5e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzKeA_GAxKda",
        "outputId": "86fae192-ceff-4344-d719-4bdc8f4a173f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1429s\u001b[0m 418ms/step - accuracy: 0.0227 - loss: 5.2228\n",
            "Epoch 2/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.1093 - loss: 4.5220\n",
            "Epoch 3/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 400ms/step - accuracy: 0.1822 - loss: 4.1156\n",
            "Epoch 4/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.2480 - loss: 3.8023\n",
            "Epoch 5/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.3105 - loss: 3.5224\n",
            "Epoch 6/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 399ms/step - accuracy: 0.3713 - loss: 3.2671\n",
            "Epoch 7/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.4245 - loss: 3.0441\n",
            "Epoch 8/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 400ms/step - accuracy: 0.4747 - loss: 2.8538\n",
            "Epoch 9/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.5150 - loss: 2.7031\n",
            "Epoch 10/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.5516 - loss: 2.5669\n",
            "Epoch 11/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.5809 - loss: 2.4616\n",
            "Epoch 12/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.6082 - loss: 2.3649\n",
            "Epoch 13/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.6318 - loss: 2.2854\n",
            "Epoch 14/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.6500 - loss: 2.2224\n",
            "Epoch 15/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.6656 - loss: 2.1682\n",
            "Epoch 16/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 400ms/step - accuracy: 0.6779 - loss: 2.1296\n",
            "Epoch 17/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.6928 - loss: 2.0817\n",
            "Epoch 18/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7043 - loss: 2.0421\n",
            "Epoch 19/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.7141 - loss: 2.0144\n",
            "Epoch 20/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.7215 - loss: 1.9870\n",
            "Epoch 21/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7282 - loss: 1.9660\n",
            "Epoch 22/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.7322 - loss: 1.9519\n",
            "Epoch 23/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7406 - loss: 1.9249\n",
            "Epoch 24/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7455 - loss: 1.9063\n",
            "Epoch 25/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 399ms/step - accuracy: 0.7499 - loss: 1.8938\n",
            "Epoch 26/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 400ms/step - accuracy: 0.7546 - loss: 1.8796\n",
            "Epoch 27/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 399ms/step - accuracy: 0.7582 - loss: 1.8660\n",
            "Epoch 28/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7608 - loss: 1.8556\n",
            "Epoch 29/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 399ms/step - accuracy: 0.7639 - loss: 1.8451\n",
            "Epoch 30/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7660 - loss: 1.8358\n",
            "Epoch 31/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7710 - loss: 1.8195\n",
            "Epoch 32/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7740 - loss: 1.8118\n",
            "Epoch 33/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 399ms/step - accuracy: 0.7757 - loss: 1.8044\n",
            "Epoch 34/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7781 - loss: 1.7959\n",
            "Epoch 35/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7802 - loss: 1.7884\n",
            "Epoch 36/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1267s\u001b[0m 400ms/step - accuracy: 0.7829 - loss: 1.7795\n",
            "Epoch 37/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 400ms/step - accuracy: 0.7815 - loss: 1.7779\n",
            "Epoch 38/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 400ms/step - accuracy: 0.7876 - loss: 1.7659\n",
            "Epoch 39/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7873 - loss: 1.7643\n",
            "Epoch 40/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 399ms/step - accuracy: 0.7881 - loss: 1.7595\n"
          ]
        }
      ],
      "source": [
        "optimizer = tfo.AdamW(learning_rate=0.001, weight_decay=0.05, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(\n",
        "    combined_ds,\n",
        "    epochs=40,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w51atERh3LcN"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P5lqat5VyCAz",
        "outputId": "c63bfb20-2f90-4354-ccd6-0c4e50bb3e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 291ms/step - accuracy: 0.6017 - loss: 1.7162\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.697739601135254, 0.6047999858856201]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_ds)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}